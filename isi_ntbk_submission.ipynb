{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Marko Zlatic ISI/Esri Student Competition 2023 Python Code\n",
    "\n",
    "**This Python code was created to uphold requirements for the ISI/Esri Student Competition 2023.**\n",
    "\n",
    "The Python code below is used to output a csv file containing all the locations for predicted fires and their respected causes from 2022 to 2102. XGBoost, as well as, Sklearn KMeans and DBSCAN were the primary machine learning algorithms used to dictate the predicted fire cause and at what location. An XGBoost regressor was used to carry out the final computation and an R-Squared score dictated the accuracy of the model.\n",
    "\n",
    "The source dataset used to produce the predictions is from the Canadian Wildland Fire Information System (CWFIS) Fire History Data found [here](\"https://cwfis.cfs.nrcan.gc.ca/datamart\").\n",
    "\n",
    "The main feature layer powering this web application can be found [here](\"https://services1.arcgis.com/0MSEUqKaxRlEPj5g/ArcGIS/rest/services/Forest_Fire_Prediction_in_Canada_8_Years/FeatureServer\").\n",
    "\n",
    "The web application hosting the results can be found in [GitHub](\"https://github.com/mzlatic1/MZ_ISI_Esri_Student_Competition/blob/gh-pages/isi_cmp_html.html\") for the source code and can also be viewed from the JSbin hosted link [here](\"https://output.jsbin.com/lohawuv\").\n",
    "\n",
    "Author Info:<br/>\n",
    "Name: Marko Zlatic<br/>\n",
    "Date: May 28, 2023<br/>\n",
    "Purpose: ISI/Esri Student Competition 2023<br/>\n",
    "Student Status: Graduate<br/>\n",
    "Program: MSc. Geographic Information Systems<br/>\n",
    "University: Johns Hopkins University\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Import all necessary packages and modules\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from xgboost import XGBRegressor\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:55:28.378507Z",
     "start_time": "2023-05-29T00:55:22.425993400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 1: Data Manipulation.** ArcGIS Pro was used first to prep the initial dataset (see StoryMaps). Geopandas was used to read the imported feature class, however, arcpy's TableToExcel_management() function could have been used export the features then read the spreadsheet via Pandas. Briefly mentioned, ArcGIS Pro was used to first prep the shapefile and exporting to a local GDB. The dataframe is then manipulated to ensure it is adequate to run through the machine learning model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load data\n",
    "gdb = os.path.join(os.path.split(os.getcwd())[0], 'ISI_Esri_Competition.gdb')\n",
    "\n",
    "fire_points = gpd.read_file(gdb, layer='NFDB_point_20220901_CLEAN')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:08.017690400Z",
     "start_time": "2023-05-29T00:55:28.377506900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   FID SRC_AGENCY      FIRE_ID FIRENAME  LATITUDE  LONGITUDE  YEAR  MONTH  \\\n0    0         BC  1953-G00041      NaN    59.963   -128.172  1953      5   \n1    1         BC  1950-R00028      NaN    59.318   -132.172  1950      6   \n2    2         BC  1950-G00026      NaN    59.876   -131.922  1950      6   \n3    3         BC  1951-R00097      NaN    59.760   -132.808  1951      7   \n4    4         BC  1952-G00116      NaN    59.434   -126.172  1952      6   \n\n   DAY                   REP_DATE  ... CFS_NOTE1 CFS_NOTE2  \\\n0   26  1953-05-26T00:00:01+00:00  ...       NaN       NaN   \n1   22  1950-06-22T00:00:01+00:00  ...       NaN       NaN   \n2    4  1950-06-04T00:00:01+00:00  ...       NaN       NaN   \n3   15  1951-07-15T00:00:01+00:00  ...       NaN       NaN   \n4   12  1952-06-12T00:00:01+00:00  ...       NaN       NaN   \n\n                    ACQ_DATE  SRC_AGY2 ECOZONE ECOZ_REF          ECOZ_NAME  \\\n0  2020-05-05T00:00:00+00:00        BC      12       12  Boreal Cordillera   \n1  2020-05-05T00:00:00+00:00        BC      12       12  Boreal Cordillera   \n2  2020-05-05T00:00:00+00:00        BC      12       12  Boreal Cordillera   \n3  2020-05-05T00:00:00+00:00        BC      12       12  Boreal Cordillera   \n4  2020-05-05T00:00:00+00:00        BC      12       12  Boreal Cordillera   \n\n             ECOZ_NOM fire_cause                          geometry  \n0  CordillCre boreale          1  POINT (-1720729.243 1659436.548)  \n1  CordillCre boreale          3  POINT (-1944085.814 1715215.898)  \n2  CordillCre boreale          1  POINT (-1899364.262 1758150.284)  \n3  CordillCre boreale          1  POINT (-1946555.179 1774478.027)  \n4  CordillCre boreale          1  POINT (-1652703.113 1556258.550)  \n\n[5 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FID</th>\n      <th>SRC_AGENCY</th>\n      <th>FIRE_ID</th>\n      <th>FIRENAME</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>YEAR</th>\n      <th>MONTH</th>\n      <th>DAY</th>\n      <th>REP_DATE</th>\n      <th>...</th>\n      <th>CFS_NOTE1</th>\n      <th>CFS_NOTE2</th>\n      <th>ACQ_DATE</th>\n      <th>SRC_AGY2</th>\n      <th>ECOZONE</th>\n      <th>ECOZ_REF</th>\n      <th>ECOZ_NAME</th>\n      <th>ECOZ_NOM</th>\n      <th>fire_cause</th>\n      <th>geometry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>BC</td>\n      <td>1953-G00041</td>\n      <td>NaN</td>\n      <td>59.963</td>\n      <td>-128.172</td>\n      <td>1953</td>\n      <td>5</td>\n      <td>26</td>\n      <td>1953-05-26T00:00:01+00:00</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-05-05T00:00:00+00:00</td>\n      <td>BC</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>1</td>\n      <td>POINT (-1720729.243 1659436.548)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>BC</td>\n      <td>1950-R00028</td>\n      <td>NaN</td>\n      <td>59.318</td>\n      <td>-132.172</td>\n      <td>1950</td>\n      <td>6</td>\n      <td>22</td>\n      <td>1950-06-22T00:00:01+00:00</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-05-05T00:00:00+00:00</td>\n      <td>BC</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>3</td>\n      <td>POINT (-1944085.814 1715215.898)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>BC</td>\n      <td>1950-G00026</td>\n      <td>NaN</td>\n      <td>59.876</td>\n      <td>-131.922</td>\n      <td>1950</td>\n      <td>6</td>\n      <td>4</td>\n      <td>1950-06-04T00:00:01+00:00</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-05-05T00:00:00+00:00</td>\n      <td>BC</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>1</td>\n      <td>POINT (-1899364.262 1758150.284)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>BC</td>\n      <td>1951-R00097</td>\n      <td>NaN</td>\n      <td>59.760</td>\n      <td>-132.808</td>\n      <td>1951</td>\n      <td>7</td>\n      <td>15</td>\n      <td>1951-07-15T00:00:01+00:00</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-05-05T00:00:00+00:00</td>\n      <td>BC</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>1</td>\n      <td>POINT (-1946555.179 1774478.027)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>BC</td>\n      <td>1952-G00116</td>\n      <td>NaN</td>\n      <td>59.434</td>\n      <td>-126.172</td>\n      <td>1952</td>\n      <td>6</td>\n      <td>12</td>\n      <td>1952-06-12T00:00:01+00:00</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2020-05-05T00:00:00+00:00</td>\n      <td>BC</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>1</td>\n      <td>POINT (-1652703.113 1556258.550)</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 29 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_points.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:08.053690200Z",
     "start_time": "2023-05-29T00:57:08.017690400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# remove unnecessary fields\n",
    "fields_2_keep = ['SRC_AGENCY', 'LATITUDE', 'LONGITUDE', 'YEAR', 'MONTH', 'DAY', 'DECADE', 'SIZE_HA', 'CAUSE', 'ECOZONE', 'ECOZ_REF', 'ECOZ_NAME', 'ECOZ_NOM']\n",
    "fire_points.drop(columns=[col for col in list(fire_points.columns) if col not in fields_2_keep], axis=1, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:08.144690Z",
     "start_time": "2023-05-29T00:57:08.049690100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# removed data points that would hinder the model to produce robust results\n",
    "fire_points = fire_points[fire_points.notnull().all(1)]\n",
    "fire_points.query(\"SIZE_HA > 0 & YEAR >= 1950\", inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:08.504862900Z",
     "start_time": "2023-05-29T00:57:08.105690Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 381363 entries, 0 to 419843\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   SRC_AGENCY  381363 non-null  object \n",
      " 1   LATITUDE    381363 non-null  float64\n",
      " 2   LONGITUDE   381363 non-null  float64\n",
      " 3   YEAR        381363 non-null  int64  \n",
      " 4   MONTH       381363 non-null  int64  \n",
      " 5   DAY         381363 non-null  int64  \n",
      " 6   DECADE      381363 non-null  object \n",
      " 7   SIZE_HA     381363 non-null  float64\n",
      " 8   CAUSE       381363 non-null  object \n",
      " 9   ECOZONE     381363 non-null  int64  \n",
      " 10  ECOZ_REF    381363 non-null  object \n",
      " 11  ECOZ_NAME   381363 non-null  object \n",
      " 12  ECOZ_NOM    381363 non-null  object \n",
      "dtypes: float64(3), int64(4), object(6)\n",
      "memory usage: 40.7+ MB\n"
     ]
    }
   ],
   "source": [
    "fire_points.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:08.755652100Z",
     "start_time": "2023-05-29T00:57:08.505862600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The sin_transformer() was derived from a blog post created from NVIDIA's Eryk Lewinson found here: [https://developer.nvidia.com/blog/three-approaches-to-encoding-time-information-as-features-for-ml-models/ Retrieved May 28, 2023](\"https://developer.nvidia.com/blog/three-approaches-to-encoding-time-information-as-features-for-ml-models/\"). Transforming the month and day integers promotes greater accuracy for the model as months 12 and 1 (for example) are more closely related when taking the sin of the respected integers; where as, literally speaking, the numbers 1 and 12 arent so close together, when comparing the months of January and December; they're 'right next to each other'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# date transformer function\n",
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:08.771652300Z",
     "start_time": "2023-05-29T00:57:08.756652200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# format dates for model\n",
    "date_fields = {'MONTH': 12, 'DAY': 365}\n",
    "for field in date_fields:\n",
    "    col_name = field + '_SIN'\n",
    "    fire_points[col_name] = sin_transformer(date_fields[field]).fit_transform(fire_points[field])\n",
    "\n",
    "fire_points.drop(columns=list(date_fields.keys()), axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:08.850683500Z",
     "start_time": "2023-05-29T00:57:08.773652500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "  SRC_AGENCY  LATITUDE  LONGITUDE  YEAR     DECADE  SIZE_HA CAUSE  ECOZONE  \\\n0         BC    59.963   -128.172  1953  1950-1959      8.0     H       12   \n1         BC    59.318   -132.172  1950  1950-1959      8.0     L       12   \n2         BC    59.876   -131.922  1950  1950-1959  12949.9     H       12   \n3         BC    59.760   -132.808  1951  1950-1959    241.1     H       12   \n4         BC    59.434   -126.172  1952  1950-1959      1.2     H       12   \n\n  ECOZ_REF          ECOZ_NAME            ECOZ_NOM     MONTH_SIN   DAY_SIN  \n0       12  Boreal Cordillera  CordillCre boreale  5.000000e-01  0.432776  \n1       12  Boreal Cordillera  CordillCre boreale  1.224647e-16  0.369725  \n2       12  Boreal Cordillera  CordillCre boreale  1.224647e-16  0.068802  \n3       12  Boreal Cordillera  CordillCre boreale -5.000000e-01  0.255353  \n4       12  Boreal Cordillera  CordillCre boreale  1.224647e-16  0.205104  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SRC_AGENCY</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>YEAR</th>\n      <th>DECADE</th>\n      <th>SIZE_HA</th>\n      <th>CAUSE</th>\n      <th>ECOZONE</th>\n      <th>ECOZ_REF</th>\n      <th>ECOZ_NAME</th>\n      <th>ECOZ_NOM</th>\n      <th>MONTH_SIN</th>\n      <th>DAY_SIN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BC</td>\n      <td>59.963</td>\n      <td>-128.172</td>\n      <td>1953</td>\n      <td>1950-1959</td>\n      <td>8.0</td>\n      <td>H</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>5.000000e-01</td>\n      <td>0.432776</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BC</td>\n      <td>59.318</td>\n      <td>-132.172</td>\n      <td>1950</td>\n      <td>1950-1959</td>\n      <td>8.0</td>\n      <td>L</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>1.224647e-16</td>\n      <td>0.369725</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BC</td>\n      <td>59.876</td>\n      <td>-131.922</td>\n      <td>1950</td>\n      <td>1950-1959</td>\n      <td>12949.9</td>\n      <td>H</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>1.224647e-16</td>\n      <td>0.068802</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BC</td>\n      <td>59.760</td>\n      <td>-132.808</td>\n      <td>1951</td>\n      <td>1950-1959</td>\n      <td>241.1</td>\n      <td>H</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>-5.000000e-01</td>\n      <td>0.255353</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BC</td>\n      <td>59.434</td>\n      <td>-126.172</td>\n      <td>1952</td>\n      <td>1950-1959</td>\n      <td>1.2</td>\n      <td>H</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>1.224647e-16</td>\n      <td>0.205104</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_points.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:08.866683500Z",
     "start_time": "2023-05-29T00:57:08.851683500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# log the SIZE_HA field to normalize values\n",
    "fire_points['SIZE_HA_LOG'] = np.log(fire_points['SIZE_HA'])\n",
    "fire_points.drop(columns=['SIZE_HA'], axis=1, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:08.960683300Z",
     "start_time": "2023-05-29T00:57:08.868682600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "  SRC_AGENCY  LATITUDE  LONGITUDE  YEAR     DECADE CAUSE  ECOZONE ECOZ_REF  \\\n0         BC    59.963   -128.172  1953  1950-1959     H       12       12   \n1         BC    59.318   -132.172  1950  1950-1959     L       12       12   \n2         BC    59.876   -131.922  1950  1950-1959     H       12       12   \n3         BC    59.760   -132.808  1951  1950-1959     H       12       12   \n4         BC    59.434   -126.172  1952  1950-1959     H       12       12   \n\n           ECOZ_NAME            ECOZ_NOM     MONTH_SIN   DAY_SIN  SIZE_HA_LOG  \n0  Boreal Cordillera  CordillCre boreale  5.000000e-01  0.432776     2.079442  \n1  Boreal Cordillera  CordillCre boreale  1.224647e-16  0.369725     2.079442  \n2  Boreal Cordillera  CordillCre boreale  1.224647e-16  0.068802     9.468843  \n3  Boreal Cordillera  CordillCre boreale -5.000000e-01  0.255353     5.485212  \n4  Boreal Cordillera  CordillCre boreale  1.224647e-16  0.205104     0.182322  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SRC_AGENCY</th>\n      <th>LATITUDE</th>\n      <th>LONGITUDE</th>\n      <th>YEAR</th>\n      <th>DECADE</th>\n      <th>CAUSE</th>\n      <th>ECOZONE</th>\n      <th>ECOZ_REF</th>\n      <th>ECOZ_NAME</th>\n      <th>ECOZ_NOM</th>\n      <th>MONTH_SIN</th>\n      <th>DAY_SIN</th>\n      <th>SIZE_HA_LOG</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BC</td>\n      <td>59.963</td>\n      <td>-128.172</td>\n      <td>1953</td>\n      <td>1950-1959</td>\n      <td>H</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>5.000000e-01</td>\n      <td>0.432776</td>\n      <td>2.079442</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BC</td>\n      <td>59.318</td>\n      <td>-132.172</td>\n      <td>1950</td>\n      <td>1950-1959</td>\n      <td>L</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>1.224647e-16</td>\n      <td>0.369725</td>\n      <td>2.079442</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>BC</td>\n      <td>59.876</td>\n      <td>-131.922</td>\n      <td>1950</td>\n      <td>1950-1959</td>\n      <td>H</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>1.224647e-16</td>\n      <td>0.068802</td>\n      <td>9.468843</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>BC</td>\n      <td>59.760</td>\n      <td>-132.808</td>\n      <td>1951</td>\n      <td>1950-1959</td>\n      <td>H</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>-5.000000e-01</td>\n      <td>0.255353</td>\n      <td>5.485212</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>BC</td>\n      <td>59.434</td>\n      <td>-126.172</td>\n      <td>1952</td>\n      <td>1950-1959</td>\n      <td>H</td>\n      <td>12</td>\n      <td>12</td>\n      <td>Boreal Cordillera</td>\n      <td>CordillCre boreale</td>\n      <td>1.224647e-16</td>\n      <td>0.205104</td>\n      <td>0.182322</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_points.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:08.970683800Z",
     "start_time": "2023-05-29T00:57:08.924683300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381363\n"
     ]
    },
    {
     "data": {
      "text/plain": "SRC_AGENCY     0\nLATITUDE       0\nLONGITUDE      0\nYEAR           0\nDECADE         0\nCAUSE          0\nECOZONE        0\nECOZ_REF       0\nECOZ_NAME      0\nECOZ_NOM       0\nMONTH_SIN      0\nDAY_SIN        0\nSIZE_HA_LOG    0\ndtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(fire_points.index)) # number of rows\n",
    "fire_points.isna().sum() # check for any remaining null values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:09.182683700Z",
     "start_time": "2023-05-29T00:57:08.937683300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# transform the remaining character-based fields\n",
    "for column in list(fire_points.columns):\n",
    "    if fire_points[column].dtype == object and column:\n",
    "        fire_points[column] = LabelEncoder().fit_transform(fire_points[column]) + 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:09.845683Z",
     "start_time": "2023-05-29T00:57:09.183683300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 2: Running the Model.** Now that the dataframe is prepped, the custom machine learning model will now take the dataframe and first run it through the DBSCAN algorithm; this will indicate the most optimal number of clusters to use given the epsilon (EPS) variable (ie the maximum search distance). Then, with the number of optimal clusters derived, it then runs through the KMeans algorithm that categorizes each of the input training points and assigns a cluster number; this is then joined back to the main dataframe. Now with each row having a cluster ID, the dataframe is then split into training and validation subsets. Once when the dataframe is split, the training data is then input for the XGBoost regressor algorithm. Once when the regressor completes its first iteration, it's then used to predict the validation data; then becomes input for the R-Squared metric generator. If the R-Squared is less than 0.99, the EPS variable is subtracted by 0.1 until the desired R-Squared is achieved (r^2 >= 0.99). Once when the desired R-Squared is achieved, the primary dataframe is then ran through the model to produce the predictions for the next 8 decades."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "subset_4_clustering = fire_points[['LATITUDE', 'LONGITUDE', 'CAUSE']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:57:09.860683500Z",
     "start_time": "2023-05-29T00:57:09.845683Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with eps: 0.2\n",
      "Testing with eps: 0.1\n",
      "R2 Score: 0.9917404845211535 Running model with actual dataset.\n"
     ]
    }
   ],
   "source": [
    "eps = 0.2 # originally the eps was first set to 0.9, however due to runtime contains and previous QC, the source code starts at 0.2.\n",
    "while True:\n",
    "    print('Testing with eps:', eps)\n",
    "\n",
    "    # First, the main dataframe is run through the DBSCAN algorithm.\n",
    "    db_scan = DBSCAN(eps, min_samples=50, n_jobs=-1).fit(subset_4_clustering)\n",
    "    prediction = db_scan.fit_predict(subset_4_clustering)\n",
    "\n",
    "    # Then the KMeans algorithm is then run using the number of clusters from the DBSCAN results.\n",
    "    num_clusters = len(np.unique(prediction))\n",
    "    k_means = KMeans(n_clusters=num_clusters, n_init='auto', max_iter=300, random_state=42)\n",
    "    k_means.fit(subset_4_clustering)\n",
    "\n",
    "    cluster_pred = k_means.predict(subset_4_clustering)\n",
    "\n",
    "    if 'cluster_id' in list(fire_points.columns): # if the iteration needs to repeat itself, it removes the pre-existing cluster id results.\n",
    "        fire_points.drop(columns='cluster_id', axis=1, inplace=True)\n",
    "\n",
    "    # Resulting cluster IDs are then joined to the main dataframe.\n",
    "    cluster_id = pd.DataFrame(cluster_pred, columns=['cluster_id']).reset_index().rename(columns={'index': 'join_field'})\n",
    "    fire_points = fire_points.reset_index().rename(columns={'index': 'join_field'}).merge(cluster_id, on='join_field').drop(columns='join_field', axis=1)\n",
    "\n",
    "    # The main dataframe is then reorganized, and the training and validation subsets are executed.\n",
    "    reordered_fields = ['SRC_AGENCY', 'YEAR', 'MONTH_SIN', 'DAY_SIN', 'DECADE', 'ECOZONE', 'ECOZ_REF', 'ECOZ_NAME', 'ECOZ_NOM', 'SIZE_HA_LOG', 'cluster_id', 'CAUSE', 'LONGITUDE', 'LATITUDE']\n",
    "    fire_points = fire_points[reordered_fields]\n",
    "\n",
    "    x = fire_points.iloc[:, :-3]\n",
    "    y = fire_points.iloc[:, -3:]\n",
    "\n",
    "    xtrain, xvalid, ytrain, yvalid = model_selection.train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # XGBoost Regressor\n",
    "    params = {\n",
    "        'n_estimators': 500,\n",
    "        'max_leaves': 0,\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "        'gpu_id': 0,\n",
    "        'predictor': 'gpu_predictor'\n",
    "    }\n",
    "\n",
    "    xg_regress = XGBRegressor(**params) # Prep model with parameters\n",
    "    xg_regress.fit(xtrain, ytrain) # Train the regressor model\n",
    "    ypred = xg_regress.predict(xvalid) # Establish predictions with validation subset\n",
    "\n",
    "    r2 = metrics.r2_score(yvalid, ypred) # Generates an R-Squared Score\n",
    "    if r2 >= 0.99:\n",
    "        print('R2 Score:', r2, 'Running model with actual dataset.')\n",
    "        ypred = xg_regress.predict(x) # reruns predictions if desired R-Squared achieved.\n",
    "        break\n",
    "    else:\n",
    "        eps -= 0.1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:58:52.204211400Z",
     "start_time": "2023-05-29T00:57:09.864683500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 3: Final Clean and Export Results.** Although robust, the XGBoost regressor might predict values that are invalid when transcribing them back into the coded values. For example, the fire cause field was transformed and ranges from 1 through 6. If there's a predicted value that greater than 6.5, then the categorical value is 7 (rounded to the nearest whole number), which is an invalid category."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting results...\n",
      "4 rows removed.\n",
      "Script complete!\n"
     ]
    }
   ],
   "source": [
    "print('Exporting results...')\n",
    "initial_row_count = len(ypred)\n",
    "df_ypred = pd.DataFrame(ypred, columns=[\"fire_cause\", \"longitude\", \"latitude\"]).query(\"0.5 <= fire_cause < 6.5\") # query to remove invalid predictions\n",
    "final_row_count = len(df_ypred.index)\n",
    "print((initial_row_count - final_row_count), 'rows removed.')\n",
    "df_ypred['fire_cause'] = df_ypred.apply(lambda row: round(row['fire_cause']), axis=1)\n",
    "\n",
    "df_ypred.to_csv(os.path.join(os.path.split(os.getcwd())[0], 'fire_pred.csv'), index=False)\n",
    "print('Script complete!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:58:53.673851900Z",
     "start_time": "2023-05-29T00:58:52.204211400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Step 4: Using ArcGIS Pro to import the csv file and conduct final processing before publishing results as a feature layer.** The exported csv file is then imported as a feature class using the XYTableToPoint_management() arcpy geoprocessing tool. The transformed fire cause field (use to be text values, now has values ranging from 1 to 6), is then re-transformed using the arcpy.da.UpdateCursor() function (see StoryMap for more detail)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T00:58:53.689853800Z",
     "start_time": "2023-05-29T00:58:53.673851900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
